{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization (EM) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "## SETUP\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(1234)\n",
    "\n",
    "np.set_printoptions(formatter={'all':lambda x: '%.3f' % x})\n",
    "\n",
    "from IPython.display import Image\n",
    "from numpy.core.umath_tests import matrix_multiply as mm\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import bernoulli, binom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#solving for likelihood using minimization\n",
    "#https://people.duke.edu/~ccc14/sta-663/EMAlgorithm.html\n",
    "\n",
    "#define a log likelihood function\n",
    "def neg_loglik(thetas, n, xs, zs):\n",
    "    return -np.sum([binom(n, thetas[z]).logpmf(x) for (x, z) in zip(xs, zs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining initial parameters\n",
    "m = 10\n",
    "theta_A = 0.8 #weight of coin A\n",
    "theta_B = 0.3 #weight of coin B\n",
    "theta_0 = [theta_A, theta_B]\n",
    "\n",
    "#generating bernouli trials\n",
    "coin_A = bernoulli(theta_A)\n",
    "coin_B = bernoulli(theta_B)\n",
    "\n",
    "#generating dataset of coin tosses according to their weights\n",
    "xs = map(sum, [coin_A.rvs(m), coin_A.rvs(m), coin_B.rvs(m), coin_A.rvs(m), coin_B.rvs(m)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 7.6552677541114456\n",
       "     jac: array([0.000, -0.000])\n",
       " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
       "    nfev: 19\n",
       "     nit: 7\n",
       "  status: 1\n",
       " success: True\n",
       "       x: array([0.733, 0.100])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## COMPLETE INFORAMTION\n",
    "\n",
    "# Z's: Which coins (complete information)\n",
    "zs = [0, 0, 1, 0, 1] #which coin did we toss\n",
    "\n",
    "## NUMERICAL ESTIMATE, WITH COMPLETE INFORMATION\n",
    "bnds = [(0,1), (0,1)]\n",
    "minimize(neg_loglik, [0.5, 0.5], args=(m, xs, zs),\n",
    "         bounds=bnds, method='tnc', options={'maxiter': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incomplete Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "theta_A = 0.31, theta_B = 0.44, ll = -744.14\n",
      "Iteration: 2\n",
      "theta_A = 0.26, theta_B = 0.41, ll = -692.48\n",
      "Iteration: 3\n",
      "theta_A = 0.24, theta_B = 0.40, ll = -684.41\n",
      "Iteration: 4\n",
      "theta_A = 0.24, theta_B = 0.40, ll = -683.42\n",
      "Iteration: 5\n",
      "theta_A = 0.24, theta_B = 0.40, ll = -683.37\n",
      "Iteration: 6\n",
      "theta_A = 0.24, theta_B = 0.40, ll = -683.37\n"
     ]
    }
   ],
   "source": [
    "heads = [14, 33, 19, 10, 0, 17, 24, 17, 1, 36, 5, 6, 5, 13, 4, 35, 5, 5, 74, 34]\n",
    "throws = [41, 43, 23, 23, 1, 23, 36, 37, 2, 131, 5, 29, 13, 47, 10, 58, 15, 14, 100, 113]\n",
    "\n",
    "xs = np.array(zip(heads,throws))\n",
    "thetas = np.array([[0.2, 0.8], [0.7, 0.3]])\n",
    "\n",
    "\n",
    "tol = 0.005\n",
    "max_iter = 100\n",
    "\n",
    "ll_old = 0\n",
    "for i in range(max_iter):\n",
    "    ws_A = []\n",
    "    ws_B = []\n",
    "\n",
    "    vs_A = []\n",
    "    vs_B = []\n",
    "\n",
    "    ll_new = 0\n",
    "\n",
    "    # E-step: calculate probability distributions over possible completions\n",
    "    for x in xs:\n",
    "\n",
    "        # multinomial (binomial) log likelihood\n",
    "        ll_A = np.sum([x*np.log(thetas[0])])\n",
    "        ll_B = np.sum([x*np.log(thetas[1])])\n",
    "\n",
    "        # [EQN 1]\n",
    "        denom = np.exp(ll_A) + np.exp(ll_B)\n",
    "        w_A = np.exp(ll_A)/denom\n",
    "        w_B = np.exp(ll_B)/denom\n",
    "\n",
    "        ws_A.append(w_A)\n",
    "        ws_B.append(w_B)\n",
    "\n",
    "        # used for calculating theta\n",
    "        vs_A.append(np.dot(w_A, x))\n",
    "        vs_B.append(np.dot(w_B, x))\n",
    "\n",
    "        # update complete log likelihood\n",
    "        ll_new += w_A * ll_A + w_B * ll_B\n",
    "\n",
    "    # M-step: update values for parameters given current distribution\n",
    "    # [EQN 2]\n",
    "    thetas[0] = np.sum(vs_A, 0)/np.sum(vs_A)\n",
    "    thetas[1] = np.sum(vs_B, 0)/np.sum(vs_B)\n",
    "    # print distribution of z for each x and current parameter estimate\n",
    "\n",
    "    print \"Iteration: %d\" % (i+1)\n",
    "    print \"theta_A = %.2f, theta_B = %.2f, ll = %.2f\" % (thetas[0,0], thetas[1,0], ll_new)\n",
    "\n",
    "    if np.abs(ll_new - ll_old) < tol:\n",
    "        break\n",
    "    ll_old = ll_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def em(xs, thetas, max_iter=100, tol=1e-6):\n",
    "    #Expectation-maximization for coin sample problem\n",
    "\n",
    "    ll_old = -np.infty\n",
    "    for i in range(max_iter):\n",
    "        ll = np.array([np.sum(xs * np.log(theta), axis=1) for theta in thetas])\n",
    "        lik = np.exp(ll)\n",
    "        ws = lik/lik.sum(0)\n",
    "        vs = np.array([w[:, None] * xs for w in ws])\n",
    "        thetas = np.array([v.sum(0)/v.sum() for v in vs])\n",
    "        ll_new = np.sum([w*l for w, l in zip(ws, ll)])\n",
    "        if np.abs(ll_new - ll_old) < tol:\n",
    "            break\n",
    "        ll_old = ll_new\n",
    "    return i, thetas, ll_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "[0.797 0.203]\n",
      "[0.520 0.480]\n",
      "-29.868676155\n"
     ]
    }
   ],
   "source": [
    "xs = np.array([(5,5), (9,1), (8,2), (4,6), (7,3)])\n",
    "thetas = np.array([[0.6, 0.4], [0.5, 0.5]])\n",
    "\n",
    "#run the EM function\n",
    "i, thetas, ll = em(xs, thetas)\n",
    "print i\n",
    "for theta in thetas:\n",
    "    print theta\n",
    "print ll\n",
    "np.random.seed(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84.000 16.000]\n",
      " [79.000 21.000]\n",
      " [81.000 19.000]\n",
      " [77.000 23.000]\n",
      " [77.000 23.000]\n",
      " [82.000 18.000]\n",
      " [82.000 18.000]\n",
      " [77.000 23.000]\n",
      " [73.000 27.000]\n",
      " [75.000 25.000]\n",
      " [82.000 18.000]\n",
      " [80.000 20.000]\n",
      " [78.000 22.000]\n",
      " [78.000 22.000]\n",
      " [81.000 19.000]\n",
      " [79.000 21.000]\n",
      " [80.000 20.000]\n",
      " [88.000 12.000]\n",
      " [77.000 23.000]\n",
      " [75.000 25.000]\n",
      " [81.000 19.000]\n",
      " [79.000 21.000]\n",
      " [86.000 14.000]\n",
      " [81.000 19.000]\n",
      " [74.000 26.000]\n",
      " [79.000 21.000]\n",
      " [81.000 19.000]\n",
      " [77.000 23.000]\n",
      " [82.000 18.000]\n",
      " [79.000 21.000]\n",
      " [75.000 25.000]\n",
      " [81.000 19.000]\n",
      " [77.000 23.000]\n",
      " [84.000 16.000]\n",
      " [78.000 22.000]\n",
      " [78.000 22.000]\n",
      " [83.000 17.000]\n",
      " [74.000 26.000]\n",
      " [81.000 19.000]\n",
      " [75.000 25.000]\n",
      " [86.000 14.000]\n",
      " [84.000 16.000]\n",
      " [86.000 14.000]\n",
      " [78.000 22.000]\n",
      " [79.000 21.000]\n",
      " [80.000 20.000]\n",
      " [87.000 13.000]\n",
      " [79.000 21.000]\n",
      " [82.000 18.000]\n",
      " [80.000 20.000]\n",
      " [33.000 67.000]\n",
      " [34.000 66.000]\n",
      " [43.000 57.000]\n",
      " [36.000 64.000]\n",
      " [30.000 70.000]\n",
      " [42.000 58.000]\n",
      " [36.000 64.000]\n",
      " [30.000 70.000]\n",
      " [33.000 67.000]\n",
      " [33.000 67.000]\n",
      " [44.000 56.000]\n",
      " [38.000 62.000]\n",
      " [34.000 66.000]\n",
      " [31.000 69.000]\n",
      " [31.000 69.000]\n",
      " [31.000 69.000]\n",
      " [30.000 70.000]\n",
      " [40.000 60.000]\n",
      " [40.000 60.000]\n",
      " [39.000 61.000]\n",
      " [36.000 64.000]\n",
      " [36.000 64.000]\n",
      " [37.000 63.000]\n",
      " [24.000 76.000]\n",
      " [37.000 63.000]\n",
      " [37.000 63.000]\n",
      " [28.000 72.000]\n",
      " [34.000 66.000]\n",
      " [39.000 61.000]\n",
      " [33.000 67.000]\n",
      " [39.000 61.000]\n",
      " [34.000 66.000]\n",
      " [43.000 57.000]\n",
      " [35.000 65.000]\n",
      " [34.000 66.000]\n",
      " [36.000 64.000]\n",
      " [26.000 74.000]\n",
      " [29.000 71.000]\n",
      " [36.000 64.000]\n",
      " [30.000 70.000]\n",
      " [36.000 64.000]\n",
      " [33.000 67.000]\n",
      " [35.000 65.000]\n",
      " [32.000 68.000]\n",
      " [38.000 62.000]\n",
      " [31.000 69.000]\n",
      " [42.000 58.000]\n",
      " [43.000 57.000]\n",
      " [37.000 63.000]\n",
      " [40.000 60.000]]\n",
      "iteration  4\n",
      "ø:  [0.352 0.648]\n",
      "ø:  [0.798 0.202]\n",
      "log-likelihood:  -5756.59565198\n"
     ]
    }
   ],
   "source": [
    "# generate new parameters and randomized data and test EM function\n",
    "n = 100\n",
    "p0 = 0.8\n",
    "p1 = 0.35\n",
    "xs = np.concatenate([np.random.binomial(n, p0, n/2), np.random.binomial(n, p1, n/2)])\n",
    "xs = np.column_stack([xs, n-xs])\n",
    "print xs\n",
    "np.random.shuffle(xs)\n",
    "\n",
    "results = [em(xs, np.random.random((2,2))) for i in range(10)]\n",
    "i, thetas, ll =  sorted(results, key=lambda x: x[-1])[-1]\n",
    "print \"iteration \", i\n",
    "for theta in thetas:\n",
    "    print \"ø: \", theta\n",
    "print \"log-likelihood: \", ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41.000, 14.000],\n",
       "       [43.000, 33.000],\n",
       "       [23.000, 19.000],\n",
       "       [23.000, 10.000],\n",
       "       [1.000, 0.000],\n",
       "       [23.000, 17.000],\n",
       "       [36.000, 24.000],\n",
       "       [37.000, 17.000],\n",
       "       [2.000, 1.000],\n",
       "       [131.000, 36.000],\n",
       "       [5.000, 5.000],\n",
       "       [29.000, 6.000],\n",
       "       [13.000, 5.000],\n",
       "       [47.000, 13.000],\n",
       "       [10.000, 4.000],\n",
       "       [58.000, 35.000],\n",
       "       [15.000, 5.000],\n",
       "       [14.000, 5.000],\n",
       "       [100.000, 74.000],\n",
       "       [113.000, 34.000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate new parameters and randomized data and test EM function\n",
    "heads = [14, 33, 19, 10, 0, 17, 24, 17, 1, 36, 5, 6, 5, 13, 4, 35, 5, 5, 74, 34]\n",
    "throws = [41, 43, 23, 23, 1, 23, 36, 37, 2, 131, 5, 29, 13, 47, 10, 58, 15, 14, 100, 113]\n",
    "\n",
    "\n",
    "xs = zip(throws,heads)\n",
    "np.array(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  9\n",
      "ø:  [0.235 0.765]\n",
      "ø:  [0.401 0.599]\n",
      "log-likelihood:  -683.367176614\n"
     ]
    }
   ],
   "source": [
    "# generate new parameters and randomized data and test EM function\n",
    "heads = [14, 33, 19, 10, 0, 17, 24, 17, 1, 36, 5, 6, 5, 13, 4, 35, 5, 5, 74, 34]\n",
    "throws = [41, 43, 23, 23, 1, 23, 36, 37, 2, 131, 5, 29, 13, 47, 10, 58, 15, 14, 100, 113]\n",
    "\n",
    "\n",
    "xs = np.array(zip(heads,throws))\n",
    "\n",
    "n = 100\n",
    "#initial ps\n",
    "p0 = heads[0]/throws[0]\n",
    "p1 = heads[1]/throws[1]\n",
    "#np.random.shuffle(xs)\n",
    "\n",
    "results = [em(xs, np.random.random((2,2))) for i in range(10)]\n",
    "i, thetas, ll =  sorted(results, key=lambda x: x[-1])[-1]\n",
    "print \"iteration \", i\n",
    "for theta in thetas:\n",
    "    print \"ø: \", theta\n",
    "print \"log-likelihood: \", ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Formatted as a function: adapted from : https://people.duke.edu/~ccc14/sta-663/EMAlgorithm.html\n",
    "def em_gmm_orig(xs, pis, mus, sigmas, tol=0.01, max_iter=100):\n",
    "\n",
    "    n, p = xs.shape\n",
    "    k = len(pis)\n",
    "\n",
    "    ll_old = 0\n",
    "    for i in range(max_iter):\n",
    "        exp_A = []\n",
    "        exp_B = []\n",
    "        ll_new = 0\n",
    "\n",
    "        # E-step\n",
    "        ws = np.zeros((k, n))\n",
    "        for j in range(len(mus)):\n",
    "            for i in range(n):\n",
    "                ws[j, i] = pis[j] * mvn(mus[j], sigmas[j]).pdf(xs[i])\n",
    "        ws /= ws.sum(0)\n",
    "\n",
    "        # M-step\n",
    "        pis = np.zeros(k)\n",
    "        for j in range(len(mus)):\n",
    "            for i in range(n):\n",
    "                pis[j] += ws[j, i]\n",
    "        pis /= n\n",
    "\n",
    "        mus = np.zeros((k, p))\n",
    "        for j in range(k):\n",
    "            for i in range(n):\n",
    "                mus[j] += ws[j, i] * xs[i]\n",
    "            mus[j] /= ws[j, :].sum()\n",
    "\n",
    "        sigmas = np.zeros((k, p, p))\n",
    "        for j in range(k):\n",
    "            for i in range(n):\n",
    "                ys = np.reshape(xs[i]- mus[j], (2,1))\n",
    "                sigmas[j] += ws[j, i] * np.dot(ys, ys.T)\n",
    "            sigmas[j] /= ws[j,:].sum()\n",
    "\n",
    "        # update complete log likelihoood\n",
    "        ll_new = 0.0\n",
    "        for i in range(n):\n",
    "            s = 0\n",
    "            for j in range(k):\n",
    "                s += pis[j] * mvn(mus[j], sigmas[j]).pdf(xs[i])\n",
    "            ll_new += np.log(s)\n",
    "\n",
    "        if np.abs(ll_new - ll_old) < tol:\n",
    "            break\n",
    "        ll_old = ll_new\n",
    "\n",
    "    return ll_new, pis, mus, sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00632453617818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:57: DeprecationWarning: Class GMM is deprecated; The class GMM is deprecated in 0.18 and will be  removed in 0.20. Use class GaussianMixture instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/tomereldor/anaconda/lib/python2.7/site-packages/sklearn/utils/deprecation.py:75: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89502149  1.99249233]\n",
      " [-0.93856387 -1.09068318]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import mixture\n",
    "\n",
    "def q(x, y):\n",
    "\tg1 = mlab.bivariate_normal(x, y, 1.0, 1.0, -1, -1, -0.8)\n",
    "\tg2 = mlab.bivariate_normal(x, y, 1.5, 0.8, 1, 2, 0.6)\n",
    "\treturn 0.6*g1+28.4*g2/(0.6+28.4)\n",
    "\n",
    "def plot_q():\n",
    "\tfig = plt.figure()\n",
    "\tax = fig.gca(projection='3d')\n",
    "\tX = np.arange(-5, 5, 0.1)\n",
    "\tY = np.arange(-5, 5, 0.1)\n",
    "\tX, Y = np.meshgrid(X, Y)\n",
    "\tZ = q(X, Y)\n",
    "\tsurf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.get_cmap('coolwarm'),\n",
    "\t\t\tlinewidth=0, antialiased=True)\n",
    "\tfig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "\tplt.savefig('3dgauss.png')\n",
    "\tplt.clf()\n",
    "\n",
    "def sample():\n",
    "\t'''Metropolis Hastings'''\n",
    "\tN = 10000\n",
    "\ts = 10\n",
    "\tr = np.zeros(2)\n",
    "\tp = q(r[0], r[1])\n",
    "\tprint p\n",
    "\tsamples = []\n",
    "\tfor i in xrange(N):\n",
    "\t\trn = r + np.random.normal(size=2)\n",
    "\t\tpn = q(rn[0], rn[1])\n",
    "\t\tif pn >= p:\n",
    "\t\t\tp = pn\n",
    "\t\t\tr = rn\n",
    "\t\telse:\n",
    "\t\t\tu = np.random.rand()\n",
    "\t\t\tif u < pn/p:\n",
    "\t\t\t\tp = pn\n",
    "\t\t\t\tr = rn\n",
    "\t\tif i % s == 0:\n",
    "\t\t\tsamples.append(r)\n",
    "\n",
    "\tsamples = np.array(samples)\n",
    "\tplt.scatter(samples[:, 0], samples[:, 1], alpha=0.5, s=1)\n",
    "\n",
    "\t'''Plot target'''\n",
    "\tdx = 0.01\n",
    "\tx = np.arange(np.min(samples), np.max(samples), dx)\n",
    "\ty = np.arange(np.min(samples), np.max(samples), dx)\n",
    "\tX, Y = np.meshgrid(x, y)\n",
    "\tZ = q(X, Y)\n",
    "\tCS = plt.contour(X, Y, Z, 10, alpha=0.5)\n",
    "\tplt.clabel(CS, inline=1, fontsize=10)\n",
    "\tplt.savefig(\"samples.png\")\n",
    "\treturn samples\n",
    "\n",
    "def fit_samples(samples):\n",
    "\tgmix = mixture.GMM(n_components=2, covariance_type='full')\n",
    "\tgmix.fit(samples)\n",
    "\tprint gmix.means_\n",
    "\tcolors = ['r' if i==0 else 'g' for i in gmix.predict(samples)]\n",
    "\tax = plt.gca()\n",
    "\tax.scatter(samples[:,0], samples[:,1], c=colors, alpha=0.8)\n",
    "\tplt.savefig(\"class.png\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tplot_q()\n",
    "\ts = sample()\n",
    "\tfit_samples(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
